---
title: "SURE Project"
author: ""
date: "`r format(Sys.Date(), '%B %d, %Y')`"
graphics: yes
output: pdf_document
urlcolor: blue
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = T,
                      cache = T,
                      eval = T,
                      message = F,
                      warning = F,
                      fig.width = 8,
                      fig.height = 6,
                      fig.align = 'center')
library(Amelia) # to map missing data
library(here)
library(tidyverse)
library(dplyr)
library(ggplot2) 
library(caret) ## For model fitting and evaluation
library(RANN)
library(corrplot)
library(rsample)
library(yardstick) ## to evaluate a model
library(visreg)  ## For visualizing regression models
library(plotROC) ## For constructing ROC curves
library(mgcv)    ## For fitting GAM models
library(kernlab) ## Contains an example dataset
library(glmnet)  ## For fitting regularized models
library(pROC)
library(ROCR)
library(car)
library(OddsPlotty) # to plot from the caret package
library(tidymodels) # modern version of caret
library(cutpointr) # Find optimal cutoff point for binary classification
library(bestglm) # Best subset GLM : The function bestglm selects the best 
                 # subset of inputs for the glm family
library(MASS) # Stepwise regression
library(reshape2)
library(sp)
library(sf)
library(rgdal)
library(raster) 
library(terra)
library(RColorBrewer)
# library(geobr)
library(ggspatial)
library(ggrepel)
library(forcats)
library(beepr)
library(gridExtra)
library(FSSgam)
library(viridis)
library(hrbrthemes)
library(gplots)
library(beepr)
library(stringr)
```

## Objective 

Predict and project spatially the result from the models.

```{r}
# directories ----
m.dir <- here()
d.dir <- here('data')

# load info on years RCCA ----
years <- read.csv(paste0(d.dir, '/RCCA_North_Coast_sites.csv'))

# get the sites from with pre MHW data ----
# 3 or more pre MHW surveys
ncsites <- years %>%
  mutate_at(vars(site_name), list(as.factor)) %>%
  # get only sites with pre MHW data
  filter(pre.mhw.years > 2) %>%
  droplevels()
```

## 1. Load RCCA data

```{r}
df <- read.csv(paste0(d.dir, '/RCCA_kelp_inverts_NC_depth-zones_wave_clim_temp_nit_subs_orbvel_npp.csv')) %>%
  mutate_at(vars(site_name, month, year, transect, zone), list(as.factor)) %>%
  mutate(zone_new = case_when(
    transect == '1' ~ 'OUTER',
    transect == '2' ~ 'OUTER',
    transect == '3' ~ 'OUTER',
    transect == '4' ~ 'INNER',
    transect == '5' ~ 'INNER',
    transect == '6' ~ 'INNER'
  )) %>%
  dplyr::select(-zone) %>%
  rename(zone = zone_new) %>%
  mutate_at(vars(zone), list(as.factor)) %>%
  relocate(zone, .after = transect)

# get the sites for North Coast model ----
df.nc <- df %>%
  dplyr::select(-c(latitude, longitude)) %>%
  right_join(ncsites, by = c('site_name')) %>%
  droplevels() %>%
  relocate(c(latitude, longitude), .after = zone)

length(levels(df.nc$site_name))
levels(df.nc$site_name)
any(is.na(df.nc$Min_Monthly_Anomaly_Temp))
```

## 2. Choose variables and transform needed

```{r}
dat1 <- df.nc %>%
  dplyr::select(
    # Factors 
    latitude, longitude, site_name, year, transect, zone,
    # Bio vars
    den_NERLUE , den_MESFRAAD , den_STRPURAD , den_PYCHEL, den_HALRUF,
    # Nitrate vars 
    Days_10N, 
    Min_Monthly_Nitrate, 
    Max_Monthly_Nitrate,
    Mean_Monthly_Nitrate,
    Mean_Monthly_Upwelling_Nitrate,
    Max_Monthly_Anomaly_Nitrate,
    Mean_Monthly_Summer_Nitrate,
    # Temperature vars
    Days_16C ,
    Mean_Monthly_Temp ,
    Mean_Monthly_Summer_Temp,
    MHW_Upwelling_Days, 
    Min_Monthly_Anomaly_Temp,
    Max_Monthly_Anomaly_Upwelling_Temp,
    Min_Monthly_Temp, 
    Mean_Monthly_Upwelling_Temp,
    #wh.95 ,   wh.max,
    npgo_mean , mei_mean,
    # substrate
    mean_depth, mean_prob_of_rock, mean_vrm, mean_slope,
    # waves
    wh_max, wh_mean, mean_waveyear, wh_95prc,
    # Orb vel
    UBR_Mean, UBR_Max,
    # NPP
    Mean_Monthly_NPP, Max_Monthly_NPP_Upwelling, Mean_Monthly_NPP_Upwelling, Min_Monthly_NPP
  ) %>%
  # Bio transformations
  mutate(
    log_den_NERLUE = log(den_NERLUE + 1),
    log_den_MESFRAAD = log(den_MESFRAAD + 1),
    log_den_STRPURAD = log(den_STRPURAD + 1),
    log_den_PYCHEL = log(den_PYCHEL + 1),
    log_den_HALRUF = log(den_HALRUF + 1),
    log_mean_vrm = log(mean_vrm + 1)
  ) %>%
  dplyr::select(-c(den_NERLUE, den_MESFRAAD, den_STRPURAD, den_PYCHEL, den_HALRUF, mean_vrm)) %>%
  # Temperature transformations
  mutate(log_Days_16C = log(Days_16C + 1)) %>%
  dplyr::select(-c(Days_16C)) %>%
  # Orb vel transformations
  mutate(
    log_UBR_Mean = log(UBR_Mean + 1), 
    log_UBR_Max = log(UBR_Max + 1)
  ) %>%
  dplyr::select(-c(UBR_Mean, UBR_Max)) %>%
  # NPP transformations
  mutate(
    log_Mean_Monthly_NPP_Upwelling = log(Mean_Monthly_NPP_Upwelling + 1),
    log_Min_Monthly_NPP = log(Min_Monthly_NPP + 1)
  ) %>%
  dplyr::select(-c(Mean_Monthly_NPP_Upwelling, Min_Monthly_NPP))

# drop NAs ----
dat2 <- dat1 %>%
  drop_na()

levels(dat2$year)
```

## 3. Divide data into train and test

```{r}
# split data into a training set (75%), and a testing set (25%)
inTraining <- createDataPartition(dat2$log_den_NERLUE, p = 0.75, list = FALSE)
train.gam <- dat2[inTraining, ]
test.gam <- dat2[-inTraining, ]
```

## 4. Run GAM

```{r}
gam1 <- gam(formula = log_den_NERLUE ~ 
              s(log_den_STRPURAD, k = 5, bs = "cr") + # purple sea urchins
              s(Max_Monthly_Nitrate, k = 5, bs = "cr") + 
              s(wh_max, k = 5, bs = "cr") + # wave height
              s(log_UBR_Max, k = 4, bs = "cr") + # orbital velocity, continuous variables
              s(site_name, zone, bs = "re") + # zone is nested within site
              s(year, bs = "re"), # discrete variables, categorical
              # random factor
              family = tw(), data = dat2, method = 'REML')

# k: the dimension of the basis used to represent the smooth terms
# bs = 'cr': cubic regression splines
# bs = 're': random effects, penalized by a ridge penalty
```

## 5. Check GAM

```{r}
gam1$aic # model selection?
gam1$deviance # goodness of fit
summary(gam1)
gam.check(gam1) # model diagnostic plots

# The effective degrees of freedom (EDF) reflects the degree of non-linearity 
# of a curve. As the edf increasingly exceeds 2, the degree of non-linearity
# progressively increases.

# Residual plotting aims to show that there is something wrong with the model 
# assumptions.
# The key assumptions are
# 1. The assumed mean variance relationship is correct, so that scaled residuals 
# have constant variance.
# 2. The response data are independent, so that the residuals appear approximately 
# so.

# visualize responses
par(mfrow = c(3, 3), mar = c(2, 4, 3, 1))
visreg(gam1)
dev.off()
```

## 6. Predict to compare to observed

```{r}
testdata <- dat2 %>%
  dplyr::select(
    'log_den_STRPURAD', 'log_mean_vrm', 'log_UBR_Max',
    'Max_Monthly_Nitrate', 'wh_max', 'log_den_NERLUE',
    'site_name', 'zone', 'year'
  )

# fit the data
fits <- predict.gam(gam1, newdata = testdata, type = 'response', se.fit = T)

# predict average kelp per year ----
predicts.year <- testdata %>%
  data.frame(fits) %>%
  group_by(year) %>% 
  summarise(response = mean(fit, na.rm = T), se.fit = mean(se.fit, na.rm = T)) %>%
  ungroup()

ggmod.year <- predicts.year %>%
  ggplot(aes(x = year, y = response, fill = year)) +
  xlab('survey_year') + 
  ylab('') + 
  scale_fill_viridis(discrete = T) + 
  geom_bar(stat = 'identity') + 
  geom_errorbar(
    aes(ymin = response - se.fit, ymax = response + se.fit), width = 0.5
  ) + 
  theme_classic() +
  theme(axis.text.x = element_text(angle = 45, h = 1))

ggmod.year
```

## 7. Plot observed vs. predicted

```{r}
predicts.all <- testdata %>%
  data.frame(fits) %>%
  ungroup()

# plot observed vs. predicted ---- 
library(ggpmisc)

my.formula <- y ~ x

p <- predicts.all %>%
  ggplot(aes(x = fit, y = log_den_NERLUE)) + 
  geom_smooth(method = 'lm', se = FALSE, color = 'black', formula = my.formula) + 
  stat_poly_eq(
    formula = my.formula,
    aes(label = paste(..eq.label.., ..rr.label.., sep = '~~~')),
    parse = TRUE
  ) + 
  geom_point() + 
  labs(x = 'Predicted', y = 'Observed', title = 'N. luetkeana') + 
  theme_bw()

p
```

## Predict best model across all years and site that I have data for

### Depth

```{r}
## get depth ----
depth.dir <- '/Volumes/Chunting HD/SURE_Data/CA_agg_bathy_30m_wInterp'

depth.30 <- rast(paste0(depth.dir, '/depth_mean_nc.all_wInterp_30m.tif'))
depth.150 <- rast(paste0(depth.dir, '/depth_mean_nc.all_wInterp_150m_30m.tif'))
depth.300 <- rast(paste0(depth.dir, '/depth_mean_nc.all_wInterp_300m_30m.tif'))
depth.600 <- rast(paste0(depth.dir, '/depth_mean_nc.all_wInterp_600m_30m.tif'))
depth.900 <- rast(paste0(depth.dir, '/depth_mean_nc.all_wInterp_900m_30m.tif'))

n.extent <- ext(depth.300)

# depth.300 # EPSG:26910

crs1 <- 'epsg:4326'
d2 <- terra::project(depth.300, crs1) 

n.extent <- ext(d2)
```

### Rock

```{r}
## get rock ----
rock.dir <- '/Volumes/Chunting HD/SURE_Data/CA_agg_prob_rock_30m_wInterp'

rock.30 <- rast(paste0(rock.dir, '/prob_rock_nc.all_30m_wInterp.tif'))

sub.dir <- paste0(rock.dir, '/rock_NC_diff_res_30m')

rock.150 <- rast(paste0(sub.dir, '/rock_NC_150res_30m.tif'))
rock.300 <- rast(paste0(sub.dir, '/rock_NC_300res_30m.tif'))
rock.600 <- rast(paste0(sub.dir, '/rock_NC_600res_30m.tif'))
rock.900 <- rast(paste0(sub.dir, '/rock_NC_900res_30m.tif'))

rock1 <- terra::project(rock.300, crs1) 

# crop to NC 
rock2 <- crop(rock1, ext(d2))

rock3 <- resample(rock2, d2)

# Resample transfers values between non matching Raster objects (in terms of origin)
# and resolution).
```

### Env predictors

```{r}
## get Env predictors

```
